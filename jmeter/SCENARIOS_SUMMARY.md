# ðŸ“Š RÃ©capitulatif des 4 ScÃ©narios JMeter

## ðŸŽ¯ Vue d'ensemble

| ScÃ©nario | Objectif | Threads | DurÃ©e | Payload | Fichier JMX |
|----------|----------|---------|-------|---------|-------------|
| **READ-heavy** | Lectures avec relations | 50â†’100â†’200 | 30 min (3Ã—10min) | - | `read_heavy_scenario.jmx` |
| **JOIN-filter** | RequÃªtes avec JOIN | 60â†’120 | 16 min (2Ã—8min) | - | `join_filter_scenario.jmx` |
| **MIXED** | Ã‰critures sur 2 entitÃ©s | 50â†’100 | 20 min (2Ã—10min) | 1 KB | `mixed_scenario_fixed.jmx` |
| **HEAVY-body** | Payloads lourds | 30â†’60 | 16 min (2Ã—8min) | 5 KB | `heavy_body_scenario.jmx` |

---

## 1ï¸âƒ£ READ-heavy (relation incluse)

### Mix de requÃªtes :
- 50% GET /items?page=&size=50
- 20% GET /items?categoryId=...&page=&size=
- 20% GET /categories/{id}/items?page=&size=
- 10% GET /categories?page=&size=

### Configuration :
- **Palier 1** : 50 threads, ramp-up 60s, durÃ©e 600s (10 min)
- **Palier 2** : 100 threads, ramp-up 60s, durÃ©e 600s
- **Palier 3** : 200 threads, ramp-up 60s, durÃ©e 600s

### Objectif :
Tester les performances de **lecture** avec :
- RequÃªtes simples (GET /items)
- Filtres (GET /items?categoryId=...)
- Relations inverses (GET /categories/{id}/items)

### Commande :
```bash
jmeter -n -t jmeter/read_heavy_scenario.jmx \
  -l jmeter/results/variant_D_read_heavy.jtl \
  -e -o jmeter/results/variant_D_read_heavy_report
```

---

## 2ï¸âƒ£ JOIN-filter ciblÃ©

### Mix de requÃªtes :
- 70% GET /items?categoryId=...&page=&size=
- 30% GET /items/{id}

### Configuration :
- **Palier 1** : 60 threads, ramp-up 60s, durÃ©e 480s (8 min)
- **Palier 2** : 120 threads, ramp-up 60s, durÃ©e 480s

### Objectif :
Tester spÃ©cifiquement les performances des **JOIN** :
- Filtre par categoryId (nÃ©cessite un JOIN entre Item et Category)
- DÃ©tection du problÃ¨me N+1
- Comparaison avec/sans fetch join

### Commande :
```bash
jmeter -n -t jmeter/join_filter_scenario.jmx \
  -l jmeter/results/variant_D_join_filter.jtl \
  -e -o jmeter/results/variant_D_join_filter_report
```

---

## 3ï¸âƒ£ MIXED (Ã©critures sur deux entitÃ©s)

### Mix de requÃªtes :
- 40% GET /items?page=...
- 20% POST /items (1 KB)
- 10% PUT /items/{id} (1 KB)
- 10% DELETE /items/{id}
- 10% POST /categories (0.5â€“1 KB)
- 10% PUT /categories/{id}

### Configuration :
- **Palier 1** : 50 threads, ramp-up 60s, durÃ©e 600s (10 min)
- **Palier 2** : 100 threads, ramp-up 60s, durÃ©e 600s

### Objectif :
Tester un **mix rÃ©aliste** de :
- Lectures (40%)
- Ã‰critures (60%) sur Items ET Categories
- Charge transactionnelle

### Fichiers requis :
- `item_payload_1k.json`
- `category_payload_1k.json`
- `item_ids.csv`
- `category_ids.csv`

### Commande :
```bash
jmeter -n -t jmeter/mixed_scenario_fixed.jmx \
  -l jmeter/results/variant_D_mixed.jtl \
  -e -o jmeter/results/variant_D_mixed_report
```

---

## 4ï¸âƒ£ HEAVY-body (payload 5 KB)

### Mix de requÃªtes :
- 50% POST /items (5 KB)
- 50% PUT /items/{id} (5 KB)

### Configuration :
- **Palier 1** : 30 threads, ramp-up 60s, durÃ©e 480s (8 min)
- **Palier 2** : 60 threads, ramp-up 60s, durÃ©e 480s

### Objectif :
Tester la gestion des **payloads volumineux** :
- SÃ©rialisation/dÃ©sÃ©rialisation JSON
- Bande passante rÃ©seau
- Impact sur les performances avec gros payloads

### Fichiers requis :
- `item_payload_5k.json` (~5-7 KB)
- `item_ids.csv`

### Commandes :

**Palier 1 (30 threads) - Par dÃ©faut activÃ© :**
```bash
jmeter -n -t jmeter/heavy_body_scenario.jmx \
  -l jmeter/results/variant_D_heavy_30.jtl \
  -e -o jmeter/results/variant_D_heavy_30_report
```

**Palier 2 (60 threads) - Modifier le fichier JMX :**
```bash
# 1. Ouvrir heavy_body_scenario.jmx dans un Ã©diteur
# 2. Ligne 19 : enabled="false" (Palier 1)
# 3. Ligne 126 : enabled="true" (Palier 2)
# 4. Sauvegarder

jmeter -n -t jmeter/heavy_body_scenario.jmx \
  -l jmeter/results/variant_D_heavy_60.jtl \
  -e -o jmeter/results/variant_D_heavy_60_report
```

---

## ðŸ“‹ Checklist avant chaque scÃ©nario

### PrÃ©paration :
- [ ] Application Spring Boot dÃ©marrÃ©e
- [ ] 100,000 items et 2,000 categories gÃ©nÃ©rÃ©s
- [ ] Fichiers CSV prÃ©sents et valides
- [ ] Fichiers JSON payload prÃ©sents
- [ ] `show-sql=false` dans application.properties

### Pendant le test :
- [ ] Surveiller les logs de l'application
- [ ] VÃ©rifier qu'il n'y a pas d'erreurs
- [ ] Observer la consommation CPU/RAM (top/htop)

### AprÃ¨s le test :
- [ ] Ouvrir le rapport HTML
- [ ] Collecter les mÃ©triques pour le tableau T2
- [ ] Noter les taux d'erreur
- [ ] Identifier les endpoints les plus lents

---

## ðŸŽ¯ MÃ©triques clÃ©s Ã  collecter

Pour chaque scÃ©nario, relever dans le rapport JMeter :

### Tableau T2 :
1. **RPS** (Throughput) : RequÃªtes/seconde
2. **p50** : Temps de rÃ©ponse mÃ©dian (Average approximatif)
3. **p95** : 95e percentile
4. **p99** : 99e percentile
5. **Err %** : Taux d'erreur

### Tableau T4 (JOIN-filter dÃ©taillÃ©) :
Par endpoint :
- GET /items?categoryId=... â†’ RPS, p95, Err%
- GET /items/{id} â†’ RPS, p95, Err%

### Tableau T5 (MIXED dÃ©taillÃ©) :
Par endpoint :
- GET /items â†’ RPS, p95, Err%
- POST /items â†’ RPS, p95, Err%
- PUT /items/{id} â†’ RPS, p95, Err%
- DELETE /items/{id} â†’ RPS, p95, Err%
- POST /categories â†’ RPS, p95, Err%
- PUT /categories/{id} â†’ RPS, p95, Err%

---

## ðŸš€ Ordre d'exÃ©cution recommandÃ©

1. **READ-heavy** (30 min)
   - DÃ©marre avec charge faible
   - Permet de valider le setup

2. **JOIN-filter** (16 min)
   - Test spÃ©cifique des performances de JOIN
   - Plus court

3. **MIXED Palier 1** (10 min)
   - Mix de lectures/Ã©critures
   - Charge modÃ©rÃ©e

4. **MIXED Palier 2** (10 min)
   - Charge plus Ã©levÃ©e
   - DÃ©tection des limites

5. **HEAVY-body Palier 1** (8 min)
   - Payloads lourds
   - 30 threads

6. **HEAVY-body Palier 2** (8 min)
   - Stress test avec payloads lourds
   - 60 threads

**DurÃ©e totale** : ~1h30

---

## ðŸ’¡ Conseils

### Pour optimiser les performances :
1. DÃ©sactiver les logs SQL (`show-sql=false`)
2. Augmenter la heap JVM : `export MAVEN_OPTS="-Xms1g -Xmx2g"`
3. Configurer HikariCP correctement
4. Utiliser des index sur les colonnes `category_id`

### Pour dÃ©tecter les problÃ¨mes :
1. Observer les logs pendant les tests
2. Utiliser Prometheus/Grafana si disponible
3. Analyser les requÃªtes SQL gÃ©nÃ©rÃ©es
4. Comparer avec les autres variantes (A et C)

---

## ðŸ† Objectifs de performance (indicatifs)

| ScÃ©nario | RPS cible | p95 max | Err% max |
|----------|-----------|---------|----------|
| READ-heavy | > 1000 | < 100ms | < 1% |
| JOIN-filter | > 500 | < 150ms | < 1% |
| MIXED | > 300 | < 200ms | < 2% |
| HEAVY-body | > 200 | < 300ms | < 2% |

*Note : Ces valeurs dÃ©pendent de votre matÃ©riel et configuration.*

